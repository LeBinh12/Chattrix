# ğŸ”´ CÃC Váº¤N Äá»€ TÃŒM THáº¤Y - KAFKA & DATABASE

## 1. ğŸ”´ CRITICAL: Race Condition trong Commit Offset

**Váº¥n Ä‘á»:**

```go
// Consumer batch processing but NO guarantee message in DB before commit
sess.MarkMessage(msg, "")  // Commit offset BEFORE insert complete
c.batchProcessor.Add(msg, sess) // Add to batch AFTER commit
```

**Háº­u quáº£:**

- Message commit nhÆ°ng insert vÃ o DB still ongoing â†’ Kafka thinks already processed
- Náº¿u insert fail â†’ message LOST, khÃ´ng thá»ƒ reprocess
- Dá»¯ liá»‡u máº¥t vÄ©nh viá»…n

**Giáº£i phÃ¡p:** âœ… Commit ONLY AFTER insert success

---

## 2. ğŸ”´ CRITICAL: Insert Cháº­m - KhÃ´ng cÃ³ Batch Index

**Váº¥n Ä‘á»:**

```go
func (s *MongoChatStore) SaveMessage(ctx context.Context, msg *models.Message) error {
    _, err := s.db.Collection("messages").InsertOne(ctx, msg)
    return err
}
```

- Insert tá»«ng message 1 cÃ¡i â†’ N requests = N latency
- Batch processor cÃ³ 100 messages nhÆ°ng insert 1-1 â†’ vÃ´ Ã­ch
- Database quÃ¡ táº£i tá»« lÆ°á»£ng connection lá»›n

**Háº­u quáº£:**

- Timeout, connection pool exhausted
- Cháº­m 100x so vá»›i batch insert

**Giáº£i phÃ¡p:** âœ… DÃ¹ng InsertMany (batch insert)

---

## 3. ğŸ”´ CRITICAL: Elasticsearch Index Blocking Main Thread

**Váº¥n Ä‘á»:**

```go
if biz.es != nil {
    // This blocks if ES is slow/down
    if err := biz.es.IndexMessage(ctx, msg, ...) {
        log.Printf("[ES] Error: %v", err) // Just log, but BLOCKS
    }
}
```

**Háº­u quáº£:**

- ES slow/down â†’ insert message stalls
- Message processing blocks entire batch
- Consumer lag â†’ all messages queue up

**Giáº£i phÃ¡p:** âœ… Index to ES async (fire-and-forget with retry queue)

---

## 4. ğŸ”´ CRITICAL: No Connection Pool Reuse

**Váº¥n Ä‘á»:**

```go
// In processBatch, creating NEW storage instances every batch
chatStore := storage.NewMongoChatStore(bp.db)
esChatStore := storage.NewESChatStore(bp.es)
// Creates 100 new instances per 100-msg batch
```

**Háº­u quáº£:**

- Lots of allocation/deallocation overhead
- Connection pool not utilized efficiently

**Giáº£i phÃ¡p:** âœ… Create storage once, reuse

---

## 5. ğŸŸ  HIGH: Incomplete Error Handling in Retry

**Váº¥n Ä‘á»:**

```go
for retry := 0; retry < 3; retry++ {
    _, err = chatBiz.HandleMessage(...)
    if err == nil {
        bp.commitQueue <- &commitTask{...}
        break
    }
    // Retry sleep + continue
}

if err != nil {
    log.Printf(" CRITICAL: Failed after 3 retries: %v", msg.ID.Hex(), err)
    // NO ACTION - message is LOST!
}
```

**Háº­u quáº£:**

- Failed messages not committed to Dead Letter Queue
- No way to track/recover lost messages

**Giáº£i phÃ¡p:** âœ… Send to DLQ topic + alert

---

## 6. ğŸŸ  HIGH: Validation Error Not Retried

**Váº¥n Ä‘á»:**

```go
senderExists, err := biz.store.CheckUserExists(ctx, sender)
if !senderExists {
    return nil, errors.New("sender not found")  // Immediate fail, NO RETRY
}
```

**Háº­u quáº£:**

- If sender added milliseconds later â†’ message lost
- No exponential backoff for transient failures

**Giáº£i phÃ¡p:** âœ… Retry validation with backoff

---

## 7. ğŸŸ  HIGH: Context Timeout Too Short

**Váº¥n Ä‘á»:**

```go
ctx, cancel := context.WithTimeout(context.Background(), 30*time.Second)
defer cancel()

// But batch processing + DB + ES can exceed 30s under load
```

**Háº­u quáº£:**

- Context deadline exceeded on slow batches
- Partial inserts (some messages in batch processed, some not)

**Giáº£i phÃ¡p:** âœ… Per-message timeout vs batch timeout

---

## 8. ğŸŸ¡ MEDIUM: No Batch Deduplication

**Váº¥n Ä‘á»:**

```go
// Same message can appear multiple times in Kafka
// No check if already in DB before insert
_, err := s.db.Collection("messages").InsertOne(ctx, msg)
// Unique index on msg.ID? Maybe, but not checked
```

**Háº­u quáº£:**

- Duplicate messages in DB if Kafka reprocess
- Database unique constraint error â†’ whole batch fails

**Giáº£i phÃ¡p:** âœ… Upsert with \_id, or check exists first

---

## 9. ğŸŸ¡ MEDIUM: Producer Async Fire-and-Forget

**Váº¥n Ä‘á» trong producer.go:**

```go
go c.sendToKafkaWithRetry("chat-topic", msgCopy.SenderID.Hex(), msgCopy)
// No wait for result - WebSocket response sent before Kafka ack
```

**Háº­u quáº£:**

- Client thinks message sent, but Kafka fails
- No error feedback to user

**Giáº£i phÃ¡p:** âœ… Wait for producer ack (semaphore)

---

## 10. ğŸŸ¡ MEDIUM: No Graceful Shutdown

**Váº¥n Ä‘á»:**

```go
// CloseProducer exists but not called on app shutdown
// Consumer Shutdown() exists but not guaranteed called
```

**Háº­u quáº£:**

- In-flight messages lost on restart
- Partial commits cause replay

**Giáº£i phÃ¡p:** âœ… Defer cleanup in main.go

---

## Summary

| Issue                | Severity    | Impact               | Status    |
| -------------------- | ----------- | -------------------- | --------- |
| Commit before insert | ğŸ”´ CRITICAL | Data loss            | Not Fixed |
| Insert 1-1 vs batch  | ğŸ”´ CRITICAL | Slow (100x)          | Not Fixed |
| ES blocking          | ğŸ”´ CRITICAL | Timeout cascade      | Not Fixed |
| No DLQ               | ğŸŸ  HIGH     | Silent failures      | Not Fixed |
| Short timeout        | ğŸŸ  HIGH     | Partial batches      | Not Fixed |
| No dedup             | ğŸŸ¡ MEDIUM   | Duplicates           | Not Fixed |
| Async fire-forget    | ğŸŸ¡ MEDIUM   | Client error blind   | Not Fixed |
| No shutdown hook     | ğŸŸ¡ MEDIUM   | Data loss on restart | Not Fixed |
